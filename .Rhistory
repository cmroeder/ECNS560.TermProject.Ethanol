state_centers = state_centers|>
mutate(state=str_to_lower(state))
#merging data to get enacted laws, e85 and locations together
merged_data1 <- merge(us_map, df, by.x = "region", by.y = "state", all.x = TRUE)
dot_data<- merge(df, state_centers, by = "state")
dot_data=dot_data|>
filter(state!="alaska") |>
filter(state!="hawaii")
#MAP with dots
map_plot2 <- ggplot() +
geom_map(data = merged_data1, aes(map_id = region, x = long, y = lat, fill = eth.production),
map = merged_data1, color = "black") +
scale_fill_gradient(low = "white", high = "purple", na.value = "lightgrey", guide = "legend") +
geom_point(data = dot_data, aes(x = long, y = lat, size = e85), color = "cadetblue3", alpha = 0.7) +
geom_text(data = dot_data, aes(x = long, y = lat, label = e85), size = 3, color = "black") +
labs(fill = bquote("Ethanol production (k barrels)\n(grey for NA)"), size = "Number of E85 Stations") +
ggtitle("E85 stations and Ethanol production (2021)") +
theme_void() +
theme(plot.title = element_text(size = 14, margin = margin(10, 0, 20, 0))) +
coord_fixed(ratio = 1.3)
map_plot2
ggsave("Outputs/Exploratory_Analysis/ethanol_production_e85.png", map_plot2, width = 8, height = 6, units = "in", dpi = 300)
#east cost states
east_states<- c("connecticut", "delaware", "maine", "maryland",
"massachusetts", "new hampshire", "new jersey", "rhode island")
#df_east
east_merged <- merged_data1 %>%
filter(region %in% east_states)
#dots
dots_east=dot_data %>%
filter(state %in% east_states)
map_plot3 <- ggplot() +
geom_map(data = east_merged, aes(map_id = region, x = long, y = lat, fill = eth.production),
map = east_merged, color = "black") +
scale_fill_gradient(low = "white", high = "purple", na.value = "lightgrey", guide = "legend") +
geom_point(data = dots_east, aes(x = long, y = lat, size = e85), color = "cadetblue3", alpha = 0.7) +
geom_text(data = dots_east, aes(x = long, y = lat, label = e85), size = 3, color = "black") +
labs(fill = bquote("Ethanol production (k barrels)\n(grey for NA)"), size = "Number of E85 Stations") +
ggtitle("E85 stations and Ethanol production (2021)") +
theme_void() +
theme(
plot.title = element_text(size = 14, margin = margin(10, 0, 35, 0)),
legend.text = element_text(size = 8)  # Adjust the legend text size here
) +
coord_fixed(ratio = 1.3)
map_plot3
ggsave("Outputs/Exploratory_Analysis/e85_legislations_map_east_coast.png", map_plot3, width = 8, height = 6, units = "in", dpi = 300)
map_plot2
# Load required libraries
library(ggplot2)
library(maps)
library(stringr)
#reading data
merge_final=read.csv("Data/Merging/merge_final.csv")
#creating df with total e85 and ethanol production
df <- merge_final %>%
mutate(state = str_to_lower(state)) %>%
filter(year == 2019, state != "total") %>%
select(state, e85, eth.production)
# Get the map data for all states, excluding Alaska and Hawaii
us_map <- map_data("state")
# Merge your data frame with map data
merged_data <- merge(us_map, df, by.x = "region", by.y = "state", all.x = TRUE)
#getting data for each state center to put dots there
state_centers=read_csv("Data/Cleaning/state_centers.csv")
state_centers = state_centers|>
mutate(state=str_to_lower(state))
#merging data to get enacted laws, e85 and locations together
merged_data1 <- merge(us_map, df, by.x = "region", by.y = "state", all.x = TRUE)
dot_data<- merge(df, state_centers, by = "state")
dot_data=dot_data|>
filter(state!="alaska") |>
filter(state!="hawaii")
#MAP with dots
map_plot2 <- ggplot() +
geom_map(data = merged_data1, aes(map_id = region, x = long, y = lat, fill = eth.production, filln),
map = merged_data1, color = "black") +
scale_fill_gradient(low = "white", high = "purple", na.value = "lightgrey", guide = "legend") +
geom_point(data = dot_data, aes(x = long, y = lat, size = e85), color = "cadetblue3", alpha = 0.7) +
geom_text(data = dot_data, aes(x = long, y = lat, label = e85), size = 3, color = "black") +
labs(fill = bquote("Ethanol production (k barrels)\n(grey for NA)"), size = "Number of E85 Stations") +
ggtitle("E85 stations and Ethanol production (2021)") +
theme_void() +
theme(plot.title = element_text(size = 14, margin = margin(10, 0, 20, 0))) +
coord_fixed(ratio = 1.3)
map_plot2
# Load required libraries
library(ggplot2)
library(maps)
library(stringr)
#reading data
merge_final=read.csv("Data/Merging/merge_final.csv")
#creating df with total e85 and ethanol production
df <- merge_final %>%
mutate(state = str_to_lower(state)) %>%
filter(year == 2019, state != "total") %>%
select(state, e85, eth.production)
# Get the map data for all states, excluding Alaska and Hawaii
us_map <- map_data("state")
# Merge your data frame with map data
merged_data <- merge(us_map, df, by.x = "region", by.y = "state", all.x = TRUE)
#getting data for each state center to put dots there
state_centers=read_csv("Data/Cleaning/state_centers.csv")
state_centers = state_centers|>
mutate(state=str_to_lower(state))
#merging data to get enacted laws, e85 and locations together
merged_data1 <- merge(us_map, df, by.x = "region", by.y = "state", all.x = TRUE)
dot_data<- merge(df, state_centers, by = "state")
dot_data=dot_data|>
filter(state!="alaska") |>
filter(state!="hawaii")
#MAP with dots
map_plot2 <- ggplot() +
geom_map(data = merged_data1, aes(map_id = region, x = long, y = lat, fill = eth.production),
map = merged_data1, color = "black") +
scale_fill_gradient(low = "white", high = "purple", na.value = "lightgrey", guide = "legend") +
geom_point(data = dot_data, aes(x = long, y = lat, size = e85), color = "cadetblue3", alpha = 0.7) +
geom_text(data = dot_data, aes(x = long, y = lat, label = e85), size = 3, color = "black") +
labs(fill = bquote("Ethanol production (k barrels)\n(grey for NA)"), size = "Number of E85 Stations") +
ggtitle("E85 stations and Ethanol production (2021)") +
theme_void() +
theme(plot.title = element_text(size = 14, margin = margin(10, 0, 20, 0))) +
coord_fixed(ratio = 1.3)
map_plot2
ggsave("Outputs/Exploratory_Analysis/ethanol_production_e85.png", map_plot2, width = 8, height = 6, units = "in", dpi = 300)
#east cost states
east_states<- c("connecticut", "delaware", "maine", "maryland",
"massachusetts", "new hampshire", "new jersey", "rhode island")
#df_east
east_merged <- merged_data1 %>%
filter(region %in% east_states)
#dots
dots_east=dot_data %>%
filter(state %in% east_states)
map_plot3 <- ggplot() +
geom_map(data = east_merged, aes(map_id = region, x = long, y = lat, fill = eth.production),
map = east_merged, color = "black") +
scale_fill_gradient(low = "white", high = "purple", na.value = "lightgrey", guide = "legend") +
geom_point(data = dots_east, aes(x = long, y = lat, size = e85), color = "cadetblue3", alpha = 0.7) +
geom_text(data = dots_east, aes(x = long, y = lat, label = e85), size = 3, color = "black") +
labs(fill = bquote("Ethanol production (k barrels)\n(grey for NA)"), size = "Number of E85 Stations") +
ggtitle("E85 stations and Ethanol production (2021)") +
theme_void() +
theme(
plot.title = element_text(size = 14, margin = margin(10, 0, 35, 0)),
legend.text = element_text(size = 8)  # Adjust the legend text size here
) +
coord_fixed(ratio = 1.3)
map_plot3
ggsave("Outputs/Exploratory_Analysis/e85_legislations_map_east_coast.png", map_plot3, width = 8, height = 6, units = "in", dpi = 300)
map_plot2
install.packages("imputeTS")
install.packages("FNN")
library(imputeTS)
library(FNN)
# Identify rows with missing eth_production values
missing_rows <- final_merge[is.na(df$eth_production),]
# Identify rows with missing eth_production values
missing_rows <- merge_final[is.na(df$eth_production),]
# Identify rows with missing eth_production values
missing_rows <- merge_final[is.na(merge_final$eth_production),]
missing_rows <- merge_final[is.na(merge_final$eth_production),]
# Identify rows with missing eth_production values
missing_rows <- merge_final[is.na(merge_final$eth.production),]
View(missing_rows)
missing_rows <- merge_final[is.na(merge_final$eth.production),]
merge_final_copy=merge_final
# Iterate through the missing rows and impute missing values
for (i in 1:nrow(missing_rows)) {
missing_row <- missing_rows[i, ]
# Find nearest neighbor within the same state but different year
nearest_neighbor <- knn(data = merge_final_copy[merge_final_copy$state == missing_row$state, c("year", "eth.production")],
test = missing_row[c("year", "eth_production")],
k = 1)
# Impute missing eth_production value with the nearest neighbor value
merge_final_copy$eth.production[which(is.na(merge_final_copy$eth.production) & merge_final_copy$state == missing_row$state & merge_final_copy$year == missing_row$year)] <- nearest_neighbor
}
install.packages("imputeTS")
install.packages("FNN")
install.packages("imputeTS")
install.packages("FNN")
library(imputeTS)
library(FNN)
# Identify rows with missing eth_production values
missing_rows <- merge_final_copy[is.na(merge_final_copy$eth.production),]
# Iterate through the missing rows and impute missing values
for (i in 1:nrow(missing_rows)) {
missing_row <- missing_rows[i, ]
# Find nearest neighbor within the same state but different year
nearest_neighbors <- get.knnx(x = merge_final_copy[merge_final_copy$state == missing_row$state & !is.na(merge_final_copy$eth.production),
c("year", "eth.production")],
query = missing_row[c("year", "eth.production")],
k = 1)
# Impute missing eth.production value with the nearest neighbor value
merge_final_copy$eth.production[which(is.na(merge_final_copy$eth.production) &
merge_final_copy$state == missing_row$state &
merge_final_copy$year == missing_row$year)] <-
merge_final_copy$eth.production[nearest_neighbors$nn.index]
}
missing_rows <- merge_final_copy[is.na(merge_final_copy$eth.production),]
# Iterate through the missing rows and impute missing values
for (i in 1:nrow(missing_rows)) {
missing_row <- missing_rows[i, ]
# Find indices of non-missing eth.production values within the same state
non_missing_indices <- which(!is.na(merge_final_copy$eth.production) &
merge_final_copy$state == missing_row$state)
# Calculate distances between missing_row and non-missing rows within the same state
distances <- dist(rbind(missing_row[c("year", "eth.production")],
merge_final_copy[non_missing_indices, c("year", "eth.production")]))
# Find the index of the nearest neighbor
nearest_neighbor_index <- non_missing_indices[which.min(distances)]
# Impute missing eth.production value with the nearest neighbor value
merge_final_copy$eth.production[which(is.na(merge_final_copy$eth.production) &
merge_final_copy$state == missing_row$state &
merge_final_copy$year == missing_row$year)] <-
merge_final_copy$eth.production[nearest_neighbor_index]
}
View(merge_final_copy)
map_plot2 <- ggplot() +
geom_map(data = merged_data1, aes(map_id = region, x = long, y = lat, fill = eth.production),
map = merged_data1, color = "black") +
scale_fill_gradient(low = "white", high = "purple", na.value = "white", guide = "legend") +
geom_point(data = dot_data, aes(x = long, y = lat, size = e85), color = "cadetblue3", alpha = 0.7) +
geom_text(data = dot_data, aes(x = long, y = lat, label = e85), size = 3, color = "black") +
labs(fill = bquote("Ethanol production (k barrels)"), size = "Number of E85 Stations") +
ggtitle("E85 stations and Ethanol production (2021)") +
theme_void() +
theme(plot.title = element_text(size = 14, margin = margin(10, 0, 20, 0))) +
coord_fixed(ratio = 1.3)
map_plot2
ggsave("Outputs/Exploratory_Analysis/ethanol_production_e85.png", map_plot2, width = 8, height = 6, units = "in", dpi = 300)
tinytex::install_tinytex()
install.packages('tinytex')
install.packages("tinytex")
#libraries
library(readxl)
library(dplyr)
library(dplyr)
#path to file
excel_file <- "Data/Raw/historical-station-counts.xlsx"
#list of all years because sheets are named after years
sheet_names <- as.character(seq(2007, 2019, by = 1))
#making a function
all_data <- lapply(sheet_names, function(sheet) {
data <- read_excel(excel_file, sheet = sheet, skip = 1)  # Skip first row, read header row as column names
data <- data[!is.na(data[[1]]), ]  # Remove rows where the first column is NA
data <- data[!is.na(data$E85), ]   # Remove rows where 'E85' column is NA
data$year <- sheet  # Add 'year' column with sheet name
return(data)
})
# Vertically concatenate all data frames into one
combined_data <- bind_rows(all_data)
#making function between 2020 and 2022 because data structure differs a little bit
sheet_names1 <- as.character(seq(2020, 2022, by = 1))
all_data1 <- lapply(sheet_names1, function(sheet) {
data1 <- read_excel(excel_file, sheet = sheet, skip = 1)  # Skip first row, read header row as column names
data1 <- data1[!is.na(data1[[1]]), ]  # Remove rows where the first column is NA
data1 <- data1[!is.na(data1$E85), ]   # Remove rows where 'E85' column is NA
data1$year <- sheet  # Add 'year' column with sheet name
return(data1)
})
# Vertically concatenate all data frames into one
combined_data1 <- bind_rows(all_data1)
#selecting only necessary columns
# View the combined data
years_2009_2019=combined_data |>
select(State,year,E85,Total)
years_2020_2022=combined_data1 |>
select(State, year, E85, Totald)
#renaming columns
colnames(years_2009_2019) <- c("state", "year", "e85", "total")
colnames(years_2020_2022) <- c("state", "year", "e85", "total")
#concating vertically
e85_df <- rbind(years_2009_2019, years_2020_2022)
#saving the df
e85_df$ratio_e85=e85_df$e85/e85_df$total*100
write.csv(e85_df, "Data/Cleaning/e_85.csv")
file_path = "Data/Raw/laws_and_incentives (Oct 24 2023).csv"
laws = read.csv(file_path)
#libraries
library(dplyr)
library(lubridate)
library(tidyverse)
library(naniar)
library(dplyr)
file_path = "Data/Raw/laws_and_incentives (Oct 24 2023).csv"
laws = read.csv(file_path)
#filling missing data with NA
law1 <- laws %>%
mutate_all(~ifelse(. == "", NA, .))
#counting NAs
sum(is.na(law1$Enacted.Date))
#changing format of date
law1$Status.Date = as.Date(law1$Status.Date, format = "%Y-%m-%d")
law1$status_year=year(law1$Status.Date)
#creating df with missing enacted date
filtered_data <- law1 %>%
filter(status_year > 2006) %>%
filter(is.na(Enacted.Date))
#we have 149 missing enacted dates which is a lot to drop
filtered_data$Significant.Update.Date=as.Date(filtered_data$Significant.Update.Date, format = "%Y-%m-%d")
filtered_data$Amended.Date=as.Date(filtered_data$Amended.Date, format = "%Y-%m-%d")
filtered_data2 <- filtered_data %>%
filter(is.na(Significant.Update.Date)) |>
filter(is.na(Amended.Date))
#trying to fill with mean length of law
trial1=laws
print(colnames(trial1))
date_related=list("Enacted.Date", "Amended.Date", "Archived.Date", "Repealed.Date", "Status.Date")
trial1 <- laws %>%
mutate_all(~ifelse(. == "", NA, .))
#changing data type
trial1$Enacted.Date=as.Date(trial1$Enacted.Date, format = "%Y-%m-%d")
trial1$Amended.Date=as.Date(trial1$Amended.Date, format = "%Y-%m-%d")
trial1$Archived.Date=as.Date(trial1$Archived.Date, format = "%Y-%m-%d")
trial1$Repealed.Date=as.Date(trial1$Repealed.Date, format = "%Y-%m-%d")
trial1$Status.Date=as.Date(trial1$Status.Date, format = "%Y-%m-%d")
#creating proxy of start date
trial1 <- trial1 %>%
mutate(start_date = ifelse(!is.na(Enacted.Date), as.Date(Enacted.Date),
ifelse(!is.na(Amended.Date) & !is.na(Significant.Update.Date),
pmin(as.Date(Amended.Date), as.Date(Significant.Update.Date)),
ifelse(!is.na(Amended.Date), as.Date(Amended.Date),
ifelse(!is.na(Significant.Update.Date), as.Date(Significant.Update.Date), NA))
)
)
)
#creating proxy of end date
trial1 <- trial1 %>%
mutate(end_date = ifelse(!is.na(Expired.Date), as.Date(Expired.Date),
ifelse(!is.na(Status.Date), as.Date(Status.Date), NA)))
# Calculate days_law_active, ignoring NA values
trial1 = trial1 |>
mutate(days_law_active =end_date-start_date, na.rm=TRUE) |>
mutate(days_law_active = ifelse(days_law_active < 0, NA, days_law_active))
#it looks like we have clear median and we will assume that missing laws follow median length
hist(trial1$days_law_active,
main = "Histogram of days_law_active",
xlab = "Days",
ylab = "Frequency",
col = "skyblue",
border = "black")
median_length=median(trial1$days_law_active,na.rm=TRUE) #1540 days which is 4 years
#filling start_date
trial1 <- trial1 %>%
mutate(missing_start_date = ifelse(is.na(start_date), 1, 0)) %>%
mutate(start_date = ifelse(is.na(start_date), end_date - median_length, start_date))
#now choosing only relevant columns
laws_reg <- trial1 %>%
select(State, Title, start_date, end_date, Type, Incentive.Categories, Regulation.Categories,
missing_start_date) %>%
mutate(start_date = as.Date(start_date, format = "%Y-%m-%d"),
end_date = as.Date(end_date, format = "%Y-%m-%d"),
start_year = year(start_date),
start_month = month(start_date),
start_day = day(start_date),
end_year = year(end_date),
end_month = month(end_date),
end_day = day(end_date),
tax_incentive = ifelse(Incentive.Categories == "TAX", 1, 0),
grant_incentive = ifelse(Incentive.Categories == "GNT", 1, 0),
other_incentive = ifelse(Incentive.Categories != "GNT" & Incentive.Categories != "TAX", 1, 0),
total_incentive = ifelse(!is.na(Incentive.Categories), 1, 0),
total_regulations = ifelse(!is.na(Regulation.Categories), 1, 0)) |>
mutate(across(c(tax_incentive, grant_incentive, other_incentive, total_incentive, total_regulations),
~replace_na(. , 0)))
#check that everything works
laws_reg$sum_incentives <- rowSums(laws_reg[, c("tax_incentive", "grant_incentive", "other_incentive", "total_regulations")])
#6 incentives are both regulations and incentives
#just seeing different types
type_frequencies <- table(trial1$Type)
print(type_frequencies)
#checking if incentives types and reg types have NAs
laws_reg <- laws_reg %>%
mutate(missing_law_reg = ifelse(is.na(Incentive.Categories) & is.na(Regulation.Categories), 1, 0))
sum(laws_reg$missing_law_reg)
#Now trying to expand
library(tidyr)
#if start date before June this year counts
laws_reg <- laws_reg %>%
mutate(start_year = ifelse(start_month > 6, start_year + 1, start_year))
#expanding
expand_rows <- function(row) {
data.frame(
State = row$State,
Year = seq(row$start_year, row$end_year),
Title = row$Title,
Type = row$Type,
tax_incentive = row$tax_incentive,
grant_incentive = row$grant_incentive,
other_incentive = row$other_incentive,
total_incentive = row$total_incentive,
total_regulations = row$total_regulations,
isFirstYear = ifelse(seq(row$start_year, row$end_year) == row$start_year, 1, 0)
)
}
# Apply the function to each row and combine the results into one data frame
expanded_laws_reg <- laws_reg %>%
rowwise() %>%
do(expand_rows(.)) %>%
ungroup()
#Final df
regulations_laws_final <- expanded_laws_reg %>%
select(State, Year, tax_incentive, grant_incentive, other_incentive,
total_incentive, total_regulations, isFirstYear) |>
group_by(State, Year) %>%
mutate(enacted = sum(isFirstYear),
incentives = sum(total_incentive),
tax_incentives = sum(tax_incentive),
grant_incentives = sum(grant_incentive),
other_incentives = sum(other_incentive),
regulations = sum(total_regulations)) |>
select(State, Year, enacted, incentives, tax_incentives, grant_incentives,
other_incentives, regulations) |>
distinct()
write.csv(regulations_laws_final, "Data/Cleaning/regulations_laws_final.csv")
file_path <- "Data/Cleaning/state_names.csv"
state_names <- read_csv(file_path)
file_path <- "Data/Cleaning/state_names.csv"
state_names <- read_csv(file_path)
regulations_laws_final=read_csv("Data/Cleaning/regulations_laws_final.csv")
#merging abbr and laws
names(regulations_laws_final)[names(regulations_laws_final) == 'State'] <- 'Alpha code'
regulations_laws_merged=merge(x = regulations_laws_final, y = state_names, by = "Alpha code", all.x = TRUE)
regulations_laws_merged=regulations_laws_merged|>
select(State, `Alpha code`, Year, enacted, incentives, tax_incentives, grant_incentives,
other_incentives, regulations)
names(regulations_laws_merged)[names(regulations_laws_merged) == 'State'] <- 'state'
names(regulations_laws_merged)[names(regulations_laws_merged) == 'Year'] <- 'year'
e85_df=read_csv("Data/Cleaning/e_85.csv")
e_85_merged=merge(x = e85_df, y = regulations_laws_merged, by = c("state", "year"), all.x = TRUE)
names(state_names)[names(state_names) == 'State'] <- 'state'
e_85_merged=merge(x = e_85_merged, y = state_names, by = c("state"), all.x = TRUE)
e_85_merged=e_85_merged|>
select(state, year, e85, total, ratio_e85, enacted, incentives, tax_incentives, grant_incentives,
other_incentives, regulations, `Alpha code.y`)
sum(e_85_merged$enacted)
e_85_merged=merge(x = e85_df, y = regulations_laws_merged, by = c("state", "year"), all.x = TRUE)
names(state_names)[names(state_names) == 'State'] <- 'state'
e_85_merged=merge(x = e_85_merged, y = state_names, by = c("state"), all.x = TRUE)
e_85_merged=e_85_merged|>
select(state, year, e85, total, ratio_e85, enacted, incentives, tax_incentives, grant_incentives,
other_incentives, regulations, `Alpha code.y`)
sum(e_85_merged$enacted)
#filling NAs with0
e_85_merged <- e_85_merged %>%
mutate(enacted = ifelse(is.na(enacted), 0, enacted),
incentives = ifelse(is.na(incentives), 0, incentives),
tax_incentives = ifelse(is.na(tax_incentives), 0, tax_incentives),
grant_incentives = ifelse(is.na(grant_incentives), 0, grant_incentives),
other_incentives = ifelse(is.na(other_incentives), 0, other_incentives),
regulations = ifelse(is.na(regulations), 0, regulations))
#merging with corn
file_path = "Data/Merging/merged.eth.corn.rds"
merged_corn = readRDS(file_path)
#merging everything with E85
e_85_merged <- e_85_merged %>%
select(`Alpha code.y`, state, year, e85, total, ratio_e85,
enacted, incentives,tax_incentives, grant_incentives,
other_incentives, regulations) %>%  # Rearrange columns A and B
rename(state_abb=`Alpha code.y`)  # Rename column C to NewColumn
merge_final_copy=merge(x=e_85_merged, y=merged_corn, by=c("state_abb", "year"),all.x = TRUE)
View(merge_final)
library(dplyr)
# Assuming merge_final_copy and merge_file are your data frames
# Find rows present in merge_final_copy but absent in merge_file
absent_rows <- anti_join(merge_final_copy, merge_final)
# The absent_rows data frame now contains rows from merge_final_copy that are absent in merge_file
print(absent_rows)
View(marge_final)
View(merge_final)
#merging everything
file_path <- "Data/Cleaning/state_names.csv"
state_names <- read_csv(file_path)
regulations_laws_final=read_csv("Data/Cleaning/regulations_laws_final.csv")
#merging abbr and laws
names(regulations_laws_final)[names(regulations_laws_final) == 'State'] <- 'Alpha code'
regulations_laws_merged=merge(x = regulations_laws_final, y = state_names, by = "Alpha code", all.x = TRUE)
regulations_laws_merged=regulations_laws_merged|>
select(State, `Alpha code`, Year, enacted, incentives, tax_incentives, grant_incentives,
other_incentives, regulations)
names(regulations_laws_merged)[names(regulations_laws_merged) == 'State'] <- 'state'
names(regulations_laws_merged)[names(regulations_laws_merged) == 'Year'] <- 'year'
#merge e85 and regulations
e85_df=read_csv("Data/Cleaning/e_85.csv")
e_85_merged=merge(x = e85_df, y = regulations_laws_merged, by = c("state", "year"), all.x = TRUE)
names(state_names)[names(state_names) == 'State'] <- 'state'
e_85_merged=merge(x = e_85_merged, y = state_names, by = c("state"), all.x = TRUE)
e_85_merged=e_85_merged|>
select(state, year, e85, total, ratio_e85, enacted, incentives, tax_incentives, grant_incentives,
other_incentives, regulations, `Alpha code.y`)
sum(e_85_merged$enacted)
#filling NAs with0
e_85_merged <- e_85_merged %>%
mutate(enacted = ifelse(is.na(enacted), 0, enacted),
incentives = ifelse(is.na(incentives), 0, incentives),
tax_incentives = ifelse(is.na(tax_incentives), 0, tax_incentives),
grant_incentives = ifelse(is.na(grant_incentives), 0, grant_incentives),
other_incentives = ifelse(is.na(other_incentives), 0, other_incentives),
regulations = ifelse(is.na(regulations), 0, regulations))
#merging with corn
file_path = "Data/Merging/merged.eth.corn.rds"
merged_corn = readRDS(file_path)
#merging everything with E85
e_85_merged <- e_85_merged %>%
select(`Alpha code.y`, state, year, e85, total, ratio_e85,
enacted, incentives,tax_incentives, grant_incentives,
other_incentives, regulations) %>%  # Rearrange columns A and B
rename(state_abb=`Alpha code.y`)  # Rename column C to NewColumn
merge_final_copy=merge(x=e_85_merged, y=merged_corn, by=c("state_abb", "year"),all.x = TRUE)
#states with missing corn production
write.csv(merge_final_copy, "Data/Merging/merge_final_copy.csv")
